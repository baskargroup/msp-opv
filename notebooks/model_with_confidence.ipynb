{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2e562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load the alias -> feature map\n",
    "with open(\"../data/feature_map.yaml\", \"r\") as f:\n",
    "    alias_to_feature = yaml.safe_load(f)\n",
    "\n",
    "# (optional) reverse map\n",
    "feature_to_alias = {v: k for k, v in alias_to_feature.items()}\n",
    "\n",
    "# pick aliases you want to use (start with d1, d2, d3, etc.)\n",
    "aliases = [\"c1\", \"c2\", \"c3\", \"d1\", \"d12\"]\n",
    "\n",
    "# resolve to real feature names\n",
    "input_features = [alias_to_feature[a] for a in aliases]\n",
    "\n",
    "# load data and select columns\n",
    "df = pd.read_parquet(\"../data/data.parquet\", engine=\"pyarrow\")\n",
    "\n",
    "target = 'J'\n",
    "\n",
    "X = df[input_features]\n",
    "y = df[target]\n",
    "\n",
    "# -----------------------------\n",
    "# Train-Test Split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Train Random Forest\n",
    "# -----------------------------\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d885e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changge seed\n",
    "np.random.seed(45)\n",
    "confidence_type = \"ci\"  # options: \"ci\" or \"ensemble\"\n",
    "# -----------------------------\n",
    "# Evaluate Model\n",
    "# -----------------------------\n",
    "y_test_vals = y_test.values\n",
    "y_pred_vals = y_pred.flatten()\n",
    "mse = mean_squared_error(y_test_vals, y_pred_vals)\n",
    "r2 = r2_score(y_test_vals, y_pred_vals)\n",
    "print(f\"Random Forest MSE: {mse:.4f}, R^2: {r2:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Confidence Estimation\n",
    "# -----------------------------\n",
    "all_preds = np.array([tree.predict(X_test) for tree in rf.estimators_])\n",
    "\n",
    "if confidence_type == \"ensemble\":\n",
    "    std_rf = all_preds.std(axis=0)\n",
    "    confidence = 1 - (std_rf / std_rf.max())\n",
    "elif confidence_type == \"ci\":\n",
    "    ci_lower = np.percentile(all_preds, 5, axis=0)\n",
    "    ci_upper = np.percentile(all_preds, 95, axis=0)\n",
    "    ci_width = ci_upper - ci_lower\n",
    "    confidence = 1 - (ci_width / ci_width.max())\n",
    "else:\n",
    "    raise ValueError(\"Invalid confidence_type. Choose 'ensemble' or 'ci'.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Results\n",
    "# -----------------------------\n",
    "results_df = pd.DataFrame({\n",
    "    'GT': y_test_vals,\n",
    "    'Prediction': y_pred_vals,\n",
    "    'Confidence': confidence,\n",
    "    'Absolute_Error': np.abs(y_test_vals - y_pred_vals),\n",
    "    'Percent_Error': np.abs((y_test_vals - y_pred_vals) / y_test_vals) * 100\n",
    "})\n",
    "\n",
    "if confidence_type == \"ci\":\n",
    "    results_df['CI_Lower'] = ci_lower\n",
    "    results_df['CI_Upper'] = ci_upper\n",
    "    results_df['CI_Width'] = ci_width\n",
    "    results_df['Within_CI'] = np.logical_and(y_test_vals >= ci_lower, y_test_vals <= ci_upper)\n",
    "\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce86bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Absolute_Error'].min(), results_df['Absolute_Error'].max(), results_df['Absolute_Error'].mean(), results_df['Absolute_Error'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dcd440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------------\n",
    "# # Visualization\n",
    "# # -----------------------------\n",
    "# # plt.rcParams[\"font.family\"] = \"serif\"\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# fontsize = 30\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# scatter = plt.scatter(y_test_vals, y_pred_vals, c=confidence, cmap='viridis', s=50, alpha=0.7)\n",
    "# plt.plot([min(y_test_vals), max(y_test_vals)],\n",
    "#          [min(y_test_vals), max(y_test_vals)], 'r--', label='Ideal Prediction')\n",
    "# plt.xlabel('True J', fontsize=fontsize)\n",
    "# # reduce padding between x label with ticks\n",
    "# # plt.gca().xaxis.set_label_coords(0.5, -0.09)\n",
    "# plt.ylabel('Predicted J', fontsize=fontsize)\n",
    "# cbar = plt.colorbar(scatter)\n",
    "# cbar.set_label(f'Confidence ({confidence_type})', fontsize=fontsize)\n",
    "# plt.xticks(fontsize=fontsize - 5)\n",
    "# plt.yticks(fontsize=fontsize - 5)\n",
    "# plt.legend(fontsize=fontsize - 5)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'./figures/rf_confidence_{confidence_type}_scatter.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aaafeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# -----------------------------\n",
    "# Confidence vs. Absolute Error: KDE Plot\n",
    "# -----------------------------\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.figure(figsize=(8, 8), dpi=50)\n",
    "fontsize = 35\n",
    "\n",
    "# 2D KDE plot\n",
    "sns.kdeplot(\n",
    "    x=confidence,\n",
    "    y=results_df['Absolute_Error'],\n",
    "    fill=True,  # filled contours\n",
    "    cmap=\"viridis\",\n",
    "    thresh=0.1,  # only plot above 5% of max density\n",
    "    levels=100,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Labels and aesthetics\n",
    "plt.xlabel(f'Confidence ({confidence_type})', fontsize=fontsize)\n",
    "plt.ylabel('Absolute Error', fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize - 5)\n",
    "plt.yticks(fontsize=fontsize - 5)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "# plt.xlim(0.5, 1)\n",
    "# plt.ylim(-0.2, 0.5)\n",
    "# plt.legend(fontsize=fontsize - 10)\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.savefig(f'../figures/kde.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcbbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Smoothed Prediction vs. Ground Truth with Shaded CI Band\n",
    "# -----------------------------\n",
    "from scipy.stats import binned_statistic\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"text.usetex\"] = False\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "plt.rcParams['font.family'] ='Times New Roman'\n",
    "\n",
    "plt.figure(figsize=(8.5, 8), dpi=50)\n",
    "fontsize = 35\n",
    "\n",
    "# Sort by true J for smooth plotting\n",
    "sorted_idx = np.argsort(y_test_vals)\n",
    "x_sorted = y_test_vals[sorted_idx]\n",
    "y_sorted = y_pred_vals[sorted_idx]\n",
    "ci_lower_sorted = ci_lower[sorted_idx]\n",
    "ci_upper_sorted = ci_upper[sorted_idx]\n",
    "\n",
    "# Optionally smooth with bins (optional: remove if unnecessary)\n",
    "n_bins = 20\n",
    "bin_means, bin_edges, _ = binned_statistic(x_sorted, y_sorted, statistic='mean', bins=n_bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "\n",
    "ci_lower_binned, _, _ = binned_statistic(x_sorted, ci_lower_sorted, statistic='mean', bins=n_bins)\n",
    "ci_upper_binned, _, _ = binned_statistic(x_sorted, ci_upper_sorted, statistic='mean', bins=n_bins)\n",
    "\n",
    "# Fill between CI bounds\n",
    "plt.fill_between(\n",
    "    bin_centers, \n",
    "    ci_lower_binned, \n",
    "    ci_upper_binned, \n",
    "    color='gray',\n",
    "    alpha=0.6, \n",
    "    label='5-95% CI band'\n",
    ")\n",
    "\n",
    "# Plot mean predicted value line\n",
    "plt.plot(bin_centers, bin_means, color='blue', label='Mean Prediction', linewidth=2)\n",
    "\n",
    "# Ideal y=x line\n",
    "plt.plot(bin_centers, bin_centers, 'r--', label='Ideal (y = x)', linewidth=2)\n",
    "\n",
    "# Labels and formatting\n",
    "# set xlabel(r'Partial Dependence of $J$ (mA/cm$^2$)', fontsize=tick_size-2)\n",
    "plt.xlabel(r'True J (mA/cm$^2$)', fontsize=fontsize)\n",
    "plt.gca().xaxis.set_label_coords(0.5, -0.07)\n",
    "plt.ylabel(r'Predicted J (mA/cm$^2$)', fontsize=fontsize)\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=fontsize - 5)\n",
    "plt.yticks(fontsize=fontsize - 5)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(fontsize=fontsize - 8)\n",
    "plt.tight_layout()\n",
    "# overlay the scatter plot\n",
    "plt.scatter(\n",
    "    y_test_vals, \n",
    "    y_pred_vals, \n",
    "    c=confidence, \n",
    "    cmap='viridis',\n",
    "    # cmap='binary',\n",
    "    s=15, \n",
    "    alpha=0.8, \n",
    "    # edgecolor='k', \n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "# add r2 score to the plot\n",
    "r2_text = r'R$^2$ = %.3f' % r2\n",
    "plt.text(\n",
    "    0.60, 0.15, r2_text,\n",
    "    fontsize=fontsize - 5,\n",
    "    ha='left', va='top',\n",
    "    transform=plt.gca().transAxes,\n",
    "    # bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white')\n",
    ")\n",
    "\n",
    "# confidence colorbar\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(f'Confidence ({confidence_type})', fontsize=fontsize)\n",
    "# cbar tick params\n",
    "cbar.ax.tick_params(labelsize=fontsize-5)\n",
    "# grid off\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../figures/rf_prediction_ci_band_smooth.pdf', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f628e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================== helper functions ==============================\n",
    "import numpy as np\n",
    "\n",
    "def _fractions(start_frac=0.01, step_frac=0.04, max_frac=0.99, \n",
    "               scale=\"linear\", num=50, split=0.1):\n",
    "    \"\"\"\n",
    "    Generate fractions for progressive sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    start_frac : float\n",
    "        Minimum training fraction.\n",
    "    step_frac : float\n",
    "        Step size (only used if scale='linear').\n",
    "    max_frac : float\n",
    "        Maximum training fraction.\n",
    "    scale : str, optional\n",
    "        'linear', 'log', or 'semi-log'.\n",
    "    num : int, optional\n",
    "        Number of points (for log/semi-log spacing).\n",
    "    split : float, optional\n",
    "        Split point for semi-log mode. Fractions <= split use log spacing,\n",
    "        and > split to max_frac use linear spacing.\n",
    "    \"\"\"\n",
    "    if scale == \"linear\":\n",
    "        fracs, f = [], start_frac\n",
    "        while f < max_frac - 1e-9:  # stop before max_frac\n",
    "            fracs.append(round(f, 4))\n",
    "            f += step_frac\n",
    "        if not np.isclose(fracs[-1], max_frac):\n",
    "            fracs.append(max_frac)\n",
    "        return fracs\n",
    "\n",
    "    elif scale == \"log\":\n",
    "        fracs = np.logspace(np.log10(start_frac), np.log10(max_frac), num)\n",
    "        return np.round(fracs, 4).tolist()\n",
    "\n",
    "    elif scale == \"semi-log\":\n",
    "        # logspace from start_frac to split\n",
    "        n1 = num // 2\n",
    "        n2 = num - n1\n",
    "        fracs_log = np.logspace(np.log10(start_frac), np.log10(split), n1, endpoint=False)\n",
    "        fracs_lin = np.linspace(split, max_frac, n2)\n",
    "        fracs = np.unique(np.concatenate([fracs_log, fracs_lin]))\n",
    "        return np.round(fracs, 4).tolist()\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"scale must be 'linear', 'log', or 'semi-log'\")\n",
    "\n",
    "\n",
    "def _progressive_core(X, y, model_maker, fracs, n_repeats=10, seed=42):\n",
    "    mean_train, std_train, mean_test, std_test = [], [], [], []\n",
    "    if fracs is None:\n",
    "        print(\"Using default linear fractions from 0.01 to 0.99 with step 0.04\")\n",
    "        fracs = _fractions(start_frac=0.01, step_frac=0.04, max_frac=0.99, scale=\"linear\")\n",
    "\n",
    "    for frac in tqdm(fracs):\n",
    "        r2_tr_runs, r2_te_runs = [], []\n",
    "        for r in range(n_repeats):\n",
    "            Xtr, Xte, ytr, yte = train_test_split(\n",
    "                X, y, train_size=frac, random_state=seed + 100*r\n",
    "            )\n",
    "            model = model_maker(seed)\n",
    "            model.fit(Xtr, ytr)\n",
    "            yhat_tr = model.predict(Xtr)\n",
    "            yhat_te = model.predict(Xte)\n",
    "            r2_tr_runs.append(r2_score(ytr, yhat_tr))\n",
    "            r2_te_runs.append(r2_score(yte, yhat_te))\n",
    "\n",
    "        mean_train.append(np.mean(r2_tr_runs)); std_train.append(np.std(r2_tr_runs))\n",
    "        mean_test.append(np.mean(r2_te_runs));  std_test.append(np.std(r2_te_runs))\n",
    "        # if test score is above 0.99 break\n",
    "        if mean_test[-1] > 0.999:\n",
    "            print(f\"Reached R2 > 0.99 at fraction {frac}, stopping early.\")\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        \"fractions\": fracs,\n",
    "        \"train_mean\": mean_train, \"train_std\": std_train,\n",
    "        \"test_mean\":  mean_test,  \"test_std\":  std_test\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Random Forest curve\n",
    "# -----------------------------\n",
    "def progressive_rf(\n",
    "    X, y, fracs=None,\n",
    "    n_repeats=10, seed=42,\n",
    "    rf_params=None\n",
    "):\n",
    "    if rf_params is None:\n",
    "        rf_params = dict(n_estimators=100, max_depth=None, n_jobs=-1)\n",
    "\n",
    "    def make_model(seed_):\n",
    "        return RandomForestRegressor(random_state=seed_, **rf_params)\n",
    "\n",
    "    return _progressive_core(X, y, make_model, fracs=fracs, n_repeats=n_repeats, seed=seed)\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# Config / Inputs\n",
    "# ==============================\n",
    "K = 7\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbc4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_frac = 0.001\n",
    "step_frac = 0.001\n",
    "max_frac = 0.95\n",
    "num = 30\n",
    "scale = \"log\"\n",
    "n_repeats = 10\n",
    "\n",
    "fracs = _fractions(start_frac, step_frac, max_frac, scale, num)\n",
    "print(len(fracs), fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd86e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive training for Random Forest\n",
    "# progressive_results = progressive_rf(\n",
    "#     X, y, fracs=fracs, n_repeats=n_repeats, seed=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# Extract results\n",
    "fractions = progressive_results[\"fractions\"]\n",
    "train_mean = progressive_results[\"train_mean\"]\n",
    "train_std = progressive_results[\"train_std\"]\n",
    "test_mean = progressive_results[\"test_mean\"]\n",
    "test_std = progressive_results[\"test_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ffb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and test R² scores\n",
    "fontsize = 35\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = fontsize\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fractions[:len(train_mean)], train_mean, label=\"Train R²\", color=\"blue\", marker='o')\n",
    "plt.fill_between(\n",
    "    fractions[:len(train_mean)],\n",
    "    np.array(train_mean) - np.array(train_std),\n",
    "    np.array(train_mean) + np.array(train_std),\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.plot(fractions[:len(test_mean)], test_mean, label=\"Test R²\", color=\"orange\", marker='o')\n",
    "plt.fill_between(\n",
    "    fractions[:len(test_mean)],\n",
    "    np.array(test_mean) - np.array(test_std),\n",
    "    np.array(test_mean) + np.array(test_std),\n",
    "    color=\"orange\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "# draw a dottend line at y = 0.99\n",
    "plt.axhline(y=0.99, color='k', linestyle='--', linewidth=1)\n",
    "plt.text(0.2, 0.95, 'R² = 0.99', color='k', fontsize=fontsize-15)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Training Fraction\", fontsize=fontsize)\n",
    "plt.ylabel(\"R² Score\", fontsize=fontsize)\n",
    "# plt.title(\"Progressive Training: Train vs Test R² Scores\", fontsize=fontsize)\n",
    "# three x ticks\n",
    "plt.xscale(\"log\")\n",
    "plt.xticks([0.001, 0.01, 0.1, 1], labels=[r'$10^{-3}$', r'$10^{-2}$', r'$10^{-1}$', r'$10^{0}$'], fontsize=fontsize-5)\n",
    "plt.yticks(fontsize=fontsize - 5)\n",
    "plt.legend(fontsize=fontsize - 5)\n",
    "# plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "# log scale for x-axis\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'../figures/progressive.pdf', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
